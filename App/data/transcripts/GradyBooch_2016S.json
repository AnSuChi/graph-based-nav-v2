{
  "id": "GradyBooch_2016S",
  "transcript": "and you sir who laughed the loudest you probably still are i grew up in a small town in the dusty plains of north texas getting into trouble was not an option and so i started reading calculus books for fun we call this a very bad idea especially the hal nine thousand now hal was a sentient computer designed to guide the discovery spacecraft from the earth to jupiter hal was also a flawed character for in the end he chose to value the mission over human life i believe that such fears are unfounded driven by refusal to accept the limits of our bodies and our minds beautiful complexity and grace that will extend the human experience in ways beyond our imagining i became a and as a result it takes on average thirteen minutes for a signal to travel from the earth to mars if there 's trouble there 's not enough time and so a reasonable engineering solution calls for us to put mission control inside the walls of the orion spacecraft another fascinating idea in the mission profile places humanoid robots on the surface of mars before the humans themselves arrive first to build facilities and later to serve as collaborative members of the science team as i looked at this from an engineering perspective it became very clear to me that what i needed to architect was a smart collaborative socially intelligent artificial intelligence in other words i needed to build something very much like a hal but without the homicidal tendencies let 's pause for a moment is it really possible to build an artificial intelligence in many ways this is a hard engineering problem with elements of ai not some wet hair ball of an ai problem that needs to be engineered to paraphrase alan turing i 'm not interested in building a sentient machine i 'm not building a hal all i 'm after is a simple brain something that offers the illusion of intelligence the art and the science of computing have come a long way since hal was onscreen and i 'd imagine if his inventor dr chandra were here today he 'd have a whole lot of questions for us is it really possible for us to take a system of millions upon millions of devices to read in their data streams to predict their failures and act in advance yes can we build systems that recognize objects identify emotions emote themselves play games and even read lips can we build systems that have a theory of mind this we are learning to do can we build systems that have an ethical and moral foundation this we must learn how to do so let 's accept for a moment that it 's possible to build such an artificial intelligence for this kind of mission and others the next question you must ask yourself is should we fear it every new technology brings with it some measure of trepidation when we first saw cars people lamented that we would see the destruction of the of the family when we first saw telephones come in people were worried it would destroy all civil conversation at a point in time but it 's also the case that these technologies brought to us things that extended the human experience in some profound ways i do not fear the creation of an ai like this in order to teach a system how to play a game well i would you would flowers come on but in the process i also teach it how to discern a good game from a bad game if i want to create an artificially intelligent legal assistant i will teach it some corpus of law but at the same time i am fusing with it the in scientific terms this is what we call ground truth and here 's the important point in producing these machines we are therefore teaching them a sense of our values to that end i trust an artificial intelligence the same if not more as a human who is well trained but you may ask what about rogue agents we cannot protect ourselves against all random acts of violence but the reality is such a system requires substantial training and subtle training far beyond the resources of an individual and furthermore it 's far more than just injecting an internet virus to the world where you push a button all of a sudden it 's in a million places and laptops start blowing up all over the place these kinds of substances are much larger and we 'll certainly see them coming if you look at movies such as the matrix on this theme and observes that a superintelligence might not only be dangerous it could represent an existential threat to all of humanity dr bostrom 's basic argument is that such systems will eventually have such an insatiable thirst for information that they will perhaps learn how to learn and eventually discover that they may have goals that are contrary to human needs dr bostrom has a number of followers he is supported by people such as elon musk and and stephen hawking with all due respect now there are a lot of pieces of dr bostrom 's argument to unpack and i don 't have time to unpack them all but very briefly consider this super knowing is very different than super doing hal was a threat to the discovery crew only insofar as hal commanded all aspects of the discovery so it would have to be with a would have to have dominion over all of our world this is the stuff of skynet from the movie the terminator in which we had a practically speaking it ain 't we are not building ais that control the weather that direct the tides that command us capricious chaotic humans and furthermore if such an artificial intelligence existed it would have to compete with human economies and thereby compete for resources with us and in the end don 't tell siri this we can always unplug them we are on an incredible journey of coevolution with our machines the humans we are today are not the humans we will be then to worry now about the rise of a superintelligence is in many ways a dangerous distraction because the rise of computing itself brings to us a number of human and societal issues to which we must now attend how shall i best organize society how might i and that 's the exciting thing the opportunities thank you very much"
}