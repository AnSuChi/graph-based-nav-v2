{
  "id": "TanLe_2010G",
  "transcript": "our communication with machines has always been limited to conscious and direct forms whether it 's something simple like turning on the lights with a switch or even as complex as programming robotics we communication between people on the other hand is far more complex and a lot more interesting because we take into account so much more than what is explicitly expressed we observe facial expressions body and we can intuit feelings and emotions from our dialogue with one another this actually forms a large part of our decision making process our vision is to introduce this whole new realm of human interaction into human computer interaction but it can also respond to your facial expressions and emotional and what better way to do this than by interpreting the signals naturally produced by our brain our center for control and experience as bruno mentioned isn 't an easy one for two main reasons our brain is made up of billions of active neurons around one hundred and seventy thousand km of combined axon length when these neurons interact the chemical reaction emits an electrical impulse which can be measured the majority of our functional brain is distributed over the outer surface layer of the brain and to increase the area that 's available for mental capacity the brain surface is highly folded now this cortical folding presents a significant challenge for interpreting surface electrical impulses so even though a signal may come from the same functional part of the brain by the time the structure has been folded its physical location is very different between individuals even identical twins there is no longer any consistency in the surface signals our breakthrough and therefore making it capable of working across a mass population the second challenge eeg measurements typically involve a hairnet with an array of sensors like the one that you can see here in the photo technician will put the electrodes onto the scalp using a conductive gel or paste like to invite onstage evan grant who is one of last year 's speakers who 's kindly agreed to help me to demonstrate what we 've been able to develop so the device that you see is acquisition system it doesn 't require any scalp preparation no conductive gel or paste it only takes a few minutes to put on and for the signals to settle so it gives you the freedom to move around and compared to the tens of thousands of dollars for a traditional eeg system this headset only costs a few hundred dollars now on to the detection so facial expressions as i mentioned before in emotional experiences are actually designed to work out of the box with some sensitivity adjustments available for personalization which is now evan is new to this system so what we have to do first is create a new profile for him he 's obviously not joanne so add user evan so the first thing we need to do with the cognitive suite is to start with training a neutral signal with neutral there 's nothing in particular that evan needs to do he just hangs out he 's relaxed and the idea is to establish a baseline or normal state for his because every brain is different it takes eight seconds to do this and now that that 's done we can choose a so evan choose something that you can visualize clearly in your mind evan grant let 's do so let 's choose pull so the idea here now is that evan needs to imagine the object coming forward into the screen and there 's a progress bar that will scroll across the screen while he 's doing that the first time nothing will happen because the system has no idea how he thinks about pull but maintain that thought for the entire duration of the eight seconds so one and this one is difficult because it 's all about being able to visualize something that doesn 't exist in our physical world movement based actions we do that all the time so you can visualize it but with disappear there 's really no analogies same sort of drill so one actually works even though you can only hold it for a little bit of time as i said it 's a very difficult process to imagine this and the great thing about it is that we 've only given the software one instance of how he thinks about disappear as there is a machine learning algorithm thank you evan you 're a wonderful wonderful example of the technology so as you can see before there is a leveling system built into this software so that as evan or any user becomes more with the system they can continue to add more and more detections so that the system begins to differentiate between different distinct thoughts application or device so i 'd like to show you a few examples because there are many possible applications for this new interface in games and virtual worlds for example your facial expressions can naturally and intuitively be lighting sound and effects can dynamically respond to your emotional state to heighten the experience that and moving on to some applications developed by developers and researchers around the world with robots and simple machines for example in this case flying a toy helicopter simply by thinking lift with your mind the technology can also be applied to real world applications in this example a smart home you know from the user interface of the control system to opening curtains or closing curtains and of course also to the lighting turning them on or off and finally to real life changing applications such as being able to control an electric wheelchair in this example expressions are mapped to the movement commands man now blink right to go right now blink left to turn back now smile to go straight"
}